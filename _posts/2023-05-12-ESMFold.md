---
title:  "Evolutionary-scale prediction of atomic-level protein structure with a language model(2023)"
classes: wide
date:   2023-05-12 17:29:03 +0900
categories: 
  - proteinstructure
tags:
  - language-model

---

## Intrdocution

The biological properties of a protein constrain the mutations to its sequence taht are selected through evolution, recording biology into evolutionary patterns. Beginning with Shannon's model for the entropy of text, language models of increasing complexity have been developed, which has culminated in modern large-scale attention-based architectures. We posit that the task of filling in missing amino acids in protein sequences across evolution will require a language model to understand the underlying structure that creates the patterns in the sequences. 

We discover that atomic-resolution structure emerges and continues to improve in language models over the four orders of magnitude in parameter scale. Strong correlations between the language model's understanding of the protein sequence(perplexity) and the accuracy of the structure prediction reveal a close link betwen language modeling and the learning of structure. 

We show that lanugage models enable fast end-to-end atomic-resolution structure prediction directly from sequence. Our approach leverages the evolutionary patterns that are captured by the language model to produce accruate atomic-level predictions. This removes costly aspects of the current state-of-the-art structure prediction pipeline, which eliminates the need for a multiple sequence alignment(MSA) while greatly simplifying the neural architecture used for inference. 

## Materials and Methods

### sequence dataset used to train ESM-2

UniRef50, September 2021 version, is used for the training of ESM models. The training dataset was partitioned by randomly selecting 

## Atomic-resolution structure emerges in language models trained on protein sequences

Relative to our previous generation model ESM-1b, ESM-2 introduces improvements in architecture, training parameters, and increases computational resources and data. 